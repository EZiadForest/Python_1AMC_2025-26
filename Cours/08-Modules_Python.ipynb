{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94e5922-f31d-420d-a911-566109a5bc36",
   "metadata": {},
   "source": [
    "# Des modules Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb93e2-7536-4c44-ae5e-1bf1d66d87a1",
   "metadata": {},
   "source": [
    "# Extraction de données\n",
    "\n",
    "\n",
    "\n",
    "## Web Scraping (Extraction de données web)\n",
    "\n",
    "\n",
    "### Définition :\n",
    "Le web scraping est une technique utilisée pour extraire des données spécifiques à partir de sites web. Ces données sont généralement structurées (comme des tableaux, des listes, des articles, etc.) et sont récupérées pour être analysées ou stockées.\n",
    "\n",
    "### Utilisation :\n",
    "\n",
    "Récupérer des informations comme les prix de produits, les actualités, les avis clients, etc.\n",
    "Automatiser la collecte de données à partir de pages web.\n",
    "\n",
    "### Outils courants :\n",
    "\n",
    "Bibliothèques Python : BeautifulSoup, Scrapy, Selenium.\n",
    "Outils visuels : Octoparse, ParseHub.\n",
    "\n",
    "### Exemple :\n",
    "Extraire les titres et les prix des produits d'une page e-commerce.\n",
    "\n",
    "### Capsule YT : \n",
    "https://www.youtube.com/playlist?list=PLgsHA8XfvCeV2zaWXDDBx75sPfVLYNHW6\n",
    "\n",
    "\n",
    "## Web Crawling (Indexation ou exploration web)\n",
    "\n",
    "### Définition :\n",
    "Le web crawling est un processus automatisé qui consiste à parcourir le web de manière systématique pour découvrir et indexer des pages web. Les crawlers (ou robots d'indexation) suivent les liens d'une page à l'autre.\n",
    "\n",
    "### Utilisation :\n",
    "\n",
    "Utilisé par les moteurs de recherche (comme Google) pour indexer les pages web.\n",
    "Découvrir de nouvelles pages et mettre à jour les informations existantes.\n",
    "\n",
    "### Outils courants :\n",
    "\n",
    "Bibliothèques Python : Scrapy, requests + BeautifulSoup.\n",
    "Crawlers de moteurs de recherche : Googlebot, Bingbot.\n",
    "\n",
    "### Exemple :\n",
    "Un robot qui parcourt le web pour indexer les pages et les ajouter à une base de données de moteur de recherche.\n",
    "\n",
    "## 1. Scrapy\n",
    "\n",
    "Scrapy (l’une des bibliothèques de science des données en Python les plus populaires) aide à construire des programmes d’exploration (spider bots) qui peuvent récupérer des données structurées sur le web – par exemple, des URL ou des informations de contact.  \n",
    "C’est un excellent outil pour scraper les données utilisées, par exemple, dans les modèles de Machine Learning en Python.\n",
    "\n",
    "Les développeurs l’utilisent pour collecter des données à partir d’API.   \n",
    "Ce framework à part entière suit le principe “Don’t Repeat Yourself” dans la conception de son interface.  \n",
    "En conséquence, l’outil incite les utilisateurs à écrire un code universel qui peut être réutilisé pour la construction et la mise à l’échelle de grands robots d’exploration. \n",
    "\n",
    "(lien vers le github scrapy https://github.com/scrapy/scrapy)\n",
    "\n",
    "\n",
    "Apprendre sur  YT : https://www.youtube.com/playlist?list=PLEn9o0UAh_cD9DtRDjq6kZFdU-6qSU_HZ\n",
    "\n",
    "## 2. BeautifulSoup\n",
    "\n",
    "BeautifulSoup est une autre bibliothèque très populaire pour le crawling sur le web et le scraping de données. Si vous souhaitez collecter des données disponibles sur un site web mais non via un fichier CSV ou une API, BeautifulSoup peut vous aider à les scraper et à les organiser dans le format dont vous avez besoin. \n",
    "\n",
    "(lien documentation BeautifulSoup https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30481704-5a80-4d85-b274-eceb96878cb4",
   "metadata": {},
   "source": [
    "# Traitement et modélisation des données\n",
    "\n",
    "## Traitement des données (Data Processing)\n",
    "### Définition\n",
    "Le traitement des données désigne l'ensemble des opérations visant à nettoyer, transformer, organiser et analyser des données brutes pour les rendre exploitables. Cela inclut :\n",
    "\n",
    "- Le nettoyage (suppression des doublons, gestion des valeurs manquantes).\n",
    "- La transformation (normalisation, agrégation, calcul de nouvelles variables).\n",
    "- L'exploration (statistiques descriptives, visualisation).\n",
    "\n",
    "### Outils en Python\n",
    "\n",
    "- Pandas : Pour manipuler des tableaux de données (DataFrames) et effectuer des opérations de nettoyage/transformation.\n",
    "- NumPy : Pour les calculs numériques avancés (tableaux multidimensionnels, opérations mathématiques).\n",
    "- OpenRefine (hors Python) : Pour le nettoyage interactif.\n",
    "\n",
    "### Exemples en science des matériaux/chimie\n",
    "\n",
    "#### Nettoyage :\n",
    "Supprimer les valeurs aberrantes dans un jeu de données de mesures de résistance mécanique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb9afc7-2723-43a6-8731-4192a0911a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/mesures_resistance.csv\")\n",
    "df_clean = df.dropna()  # Supprime les lignes avec des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c04ff6-9abb-4c7d-9fa5-85b304c7d939",
   "metadata": {},
   "source": [
    "#### Transformation :\n",
    "Convertir des unités (ex. : Celsius → Kelvin) ou calculer des moyennes mobiles pour lisser des courbes expérimentales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c317af-ea9b-4cdb-9a9f-55b2e39ef772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temperature_K\"] = df[\"temperature_C\"] + 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af11ea7-bb6e-4538-a403-091c96b307a3",
   "metadata": {},
   "source": [
    "#### Agrégation :\n",
    "Calculer la moyenne des propriétés d'un matériau pour différentes conditions expérimentales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4bc5115-f7f8-4e11-8163-9f3337e27010",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1943\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1943\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[1;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2460\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2458\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2460\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   2461\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/series.py:6560\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6552\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6554\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6558\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6559\u001b[0m ):\n\u001b[0;32m-> 6560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/generic.py:12439\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12433\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12434\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12437\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12438\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  12440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  12441\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/generic.py:12396\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12394\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  12397\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  12398\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/series.py:6468\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6465\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6467\u001b[0m     )\n\u001b[0;32m-> 6468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'Composite bois-plastiqueVerre sodocalciqueBéton arméPVCNitrate de boreBéton arméCuivreBéton arméVerre trempéComposite bois-plastiqueFibre de carboneFibre de carboneCuivreVerre sodocalciqueVerre quartzZirconePVCFibre de carboneCuivreVerre trempéPorcelaine' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_grouped \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2458\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2452\u001b[0m         grouped_mean,\n\u001b[1;32m   2453\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2454\u001b[0m         engine_kwargs,\n\u001b[1;32m   2455\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2456\u001b[0m     )\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2458\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2460\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   2461\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2004\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   2002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 2004\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   2005\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/internals/managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[1;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/internals/blocks.py:395\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    397\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2001\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1998\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2001\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PythonMC/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1947\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1945\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m dtype \u001b[38;5;241m=\u001b[39m ser\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby(\"condition\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e382f-436d-463c-8baf-11fab6e17118",
   "metadata": {},
   "source": [
    "## Modélisation des données (Data Modeling)\n",
    "### Définition\n",
    "La modélisation des données consiste à utiliser des algorithmes ou des équations pour représenter des phénomènes réels à partir des données. Cela inclut :\n",
    "\n",
    "- La régression (prédire une variable continue, ex. : propriété mécanique en fonction de la composition chimique).\n",
    "- La classification (catégoriser des échantillons, ex. : identifier des phases cristallines).\n",
    "- La simulation (modèles physiques ou empiriques, ex. : cinétique de réaction).\n",
    "\n",
    "### Outils en Python\n",
    "\n",
    "- Scikit-learn : Pour le machine learning (régression, classification, clustering).\n",
    "- SciPy : Pour les modèles mathématiques/physiques (équations différentielles, optimisation).\n",
    "- TensorFlow/PyTorch : Pour les modèles complexes (réseaux de neurones).\n",
    "- Statsmodels : Pour les statistiques avancées (régression linéaire/multiple).\n",
    "\n",
    "### Exemples en science des matériaux/chimie\n",
    "\n",
    "#### Régression linéaire :\n",
    "Prédire la conductivité thermique d'un matériau en fonction de sa porosité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd27d78-a690-4c34-98c4-6b6562923f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mdf[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mporosite\u001b[39m\u001b[38;5;124m\"\u001b[39m]], y\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconductivite\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X=df[[\"porosite\"]], y=df[\"conductivite\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19eb80-9a8b-4b17-ae08-acd624d18cc3",
   "metadata": {},
   "source": [
    "#### Classification :\n",
    "Classer des échantillons en fonction de leur spectre infrarouge (ex. : polymères vs céramiques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304dcac-1b85-4986-a495-58e56296a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)  # X_train = spectres, y_train = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647292b-e657-472d-9a42-7d1ff8080e39",
   "metadata": {},
   "source": [
    "#### Modèles physiques :\n",
    "Résoudre des équations différentielles pour simuler une réaction chimique avec SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7013403-3be8-47c1-85dc-5bc1a592158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "def model(y, t, k):\n",
    "    dydt = -k * y  # Loi cinétique d'ordre 1\n",
    "    return dydt\n",
    "solution = odeint(model, y0=1.0, t=temps, args=(k,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97dd3d-88ec-4578-a0e6-5b9a9a6b2088",
   "metadata": {},
   "source": [
    "#### Réseaux de neurones :\n",
    "Prédire la structure cristalline d'un matériau à partir de sa composition (avec TensorFlow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14dd44c-e6dd-4119-9f3f-c2608b5ffd46",
   "metadata": {},
   "source": [
    "## 3. NumPy\n",
    "\n",
    "NumPy (pour Numerical Python) est un outil parfait pour le calcul scientifique et la réalisation d’opérations de base et avancées avec des tableaux.\n",
    "\n",
    "La bibliothèque offre de nombreuses fonctionnalités pratiques permettant d’effectuer des opérations sur des tableaux (n-arrays) et des matrices en Python.   Elle permet de traiter des tableaux qui stockent des valeurs du même type de données et facilite l’exécution d’opérations mathématiques sur les tableaux (et leur vectorisation).   \n",
    "En fait, la vectorisation des opérations mathématiques sur le type de tableau NumPy augmente les performances et accélère le temps d’exécution. \n",
    "\n",
    "(lien github NumPy https://github.com/numpy/numpy)\n",
    "\n",
    "Si vous voulez en apprendre plus, regardez ce guide NumPy https://moncoachdata.com/blog/guide-bibliotheque-numpy/.\n",
    "\n",
    "## 4. SciPy\n",
    "\n",
    "Cette bibliothèque utile comprend des modules pour l’algèbre linéaire, l’intégration, l’optimisation et les statistiques. \n",
    "\n",
    "Sa fonctionnalité principale a été construite sur NumPy, donc ses tableaux utilisent cette bibliothèque.  \n",
    "SciPy fonctionne parfaitement pour toutes sortes de projets de programmation scientifique (sciences, mathématiques et ingénierie).  \n",
    "Il offre des routines numériques efficaces telles que l’optimisation numérique, l’intégration et d’autres dans des sous-modules. La vaste documentation rend le travail avec cette bibliothèque vraiment facile. \n",
    "\n",
    "(lien github de SciPy https://github.com/scipy/scipy)\n",
    "\n",
    "## 5. Pandas\n",
    "\n",
    "Pandas est une bibliothèque créée pour aider les développeurs à travailler intuitivement avec des données “étiquetées” et “relationnelles”.  \n",
    "\n",
    "Elle est basée sur deux structures de données principales : “Série” (unidimensionnelle, comme une liste Python) et “Dataframe” (bidimensionnelle, comme un tableau à plusieurs colonnes).   \n",
    "Pandas permet de convertir des structures de données en objets DataFrame, de gérer les données manquantes et d’ajouter/supprimer des colonnes de DataFrame, d’imputer les fichiers manquants et de tracer les données avec un histogramme ou une boîte à moustache.   \n",
    "C’est un outil indispensable pour la manipulation et la visualisation des données. \n",
    "\n",
    "(lien github Pandas https://moncoachdata.com/blog/guide-bibliotheque-pandas/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56dbc6-fac9-4629-8b49-c815afe16fdb",
   "metadata": {},
   "source": [
    "# Visualisation de données\n",
    "\n",
    "## 6. Matplotlib\n",
    "\n",
    "Matplotlib est une bibliothèque scientifique de données standard qui aide à générer des visualisations de données telles que des diagrammes et des graphiques bidimensionnels (histogrammes, diagrammes de dispersion, graphiques de coordonnées non cartésiennes). Matplotlib est l’une de ces bibliothèques de tracés qui sont vraiment utiles dans les projets de science des données – elle fournit une API orientée objet pour intégrer des tracés dans les applications.\n",
    "\n",
    "C’est grâce à cette bibliothèque que Python peut rivaliser avec des outils scientifiques comme MatLab ou Mathematica. Cependant, les développeurs doivent écrire plus de code que d’habitude en utilisant cette bibliothèque pour générer des visualisations avancées. Notez que les bibliothèques de tracés populaires fonctionnent sans problème avec Matplotlib. (lien github Matplotlib https://github.com/matplotlib/matplotlib)\n",
    "\n",
    "## 7. Seaborn\n",
    "\n",
    "Seaborn est basé sur Matplotlib et sert d’outil de Machine Learning Python utile pour la visualisation de modèles statistiques – cartes thermiques et autres types de visualisations qui résument les données et dépeignent les distributions globales. En utilisant cette bibliothèque, vous bénéficiez d’une vaste galerie de visualisations (y compris des visualisations complexes comme les séries temporelles, les tracés conjoints et les diagrammes de violon). (lien github Seaborn https://github.com/mwaskom/seaborn)\n",
    "\n",
    "## 8. Bokeh\n",
    "\n",
    "Cette bibliothèque est un excellent outil pour créer des visualisations interactives et évolutives à l’intérieur des navigateurs en utilisant des widgets JavaScript. Bokeh est totalement indépendant de Matplotlib. Elle se concentre sur l’interactivité et présente des visualisations à travers les navigateurs modernes – de manière similaire aux documents pilotés par les données (d3.js). Il offre un ensemble de graphiques, de capacités d’interaction (comme la liaison de tracés ou l’ajout de widgets JavaScript) et de style. (lien github Bokeh https://github.com/bokeh/bokeh)\n",
    "\n",
    "## 9. Plotly\n",
    "\n",
    "Cet outil web de visualisation des données qui offre de nombreux graphiques utiles prêts à l’emploi – vous pouvez les trouver sur le site Plot.ly https://plotly.com/. La bibliothèque fonctionne très bien dans les applications web interactives. Ses créateurs s’emploient à enrichir la bibliothèque avec de nouveaux graphiques et de nouvelles fonctionnalités permettant de prendre en charge plusieurs vues liées, l’animation et l’intégration de la diaphonie. (lien github Plotly https://github.com/plotly/plotly.py)\n",
    "\n",
    "## 10. pydot\n",
    "\n",
    "Cette bibliothèque permet de générer des graphes orientés et non orientés. Elle sert d’interface à Graphviz (écrit en pur Python). Vous pouvez facilement montrer la structure des graphes à l’aide de cette bibliothèque. Cela s’avère pratique lorsque vous développez des algorithmes basés sur des réseaux de neurones et des arbres de décision. (lien github pydot https://github.com/pydot/pydot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8536d06-391f-4f08-a72c-0b60dc7ce1fc",
   "metadata": {},
   "source": [
    "# \"IA\"\n",
    "\n",
    "## 11. Keras\n",
    "\n",
    "Keras est une excellente bibliothèque pour la construction de réseaux de neurones et la modélisation. Elle est très simple à utiliser et offre aux développeurs un bon degré d’extensibilité. La bibliothèque tire parti d’autres paquets (Theano ou TensorFlow) comme terminaux. De plus, Microsoft a intégré CNTK (Microsoft Cognitive Toolkit) pour servir d’autre backend. C’est un excellent choix si vous voulez expérimenter rapidement en utilisant des systèmes compacts – l’approche minimaliste de la conception est vraiment top ! (lien github Keras https://github.com/keras-team/keras)\n",
    "\n",
    "## 12. Scikit-Learn\n",
    "\n",
    "Il s’agit d’une norme industrielle pour les projets de science des données basés en Python. Scikits est un groupe de paquets de SciPy qui ont été créés pour des fonctionnalités spécifiques – par exemple, le traitement d’images. Scikit-learn utilise les opérations mathématiques de SciPy pour exposer une interface concise aux algorithmes d’apprentissage machine les plus courants.\n",
    "\n",
    "Les spécialistes des données l’utilisent pour traiter les tâches standard de Machine Learning et d’exploration de données telles que le regroupement, la régression, la sélection de modèles, la réduction de la dimensionnalité et la classification. Un autre avantage ? Il s’accompagne d’une documentation de qualité et offre des performances élevées. (lien github scikit-learn https://github.com/scikit-learn/scikit-learn)\n",
    "\n",
    "## 13. PyTorch\n",
    "\n",
    "PyTorch est un framework qui est parfait pour les data scientists qui veulent effectuer facilement des tâches de Deep Learning. L’outil permet d’effectuer des calculs de tenseurs avec une accélération GPU. Il est également utilisé pour d’autres tâches – par exemple, pour créer des graphiques de calcul dynamiques et calculer automatiquement des gradients. PyTorch est basé sur Torch, qui est une bibliothèque open-source de Deep Learning, implémentée en C, avec un habillage en Lua. (lien github PyTorch https://github.com/pytorch/pytorch)\n",
    "\n",
    "## 14. TensorFlow\n",
    "\n",
    "TensorFlow est un framework Python populaire pour le Machine Learning et le Deep Learning, qui a été développé à Google Brain. C’est le meilleur outil pour des tâches comme l’identification d’objets, la reconnaissance vocale et bien d’autres. Il permet de travailler avec des réseaux neuronaux artificiels qui doivent gérer plusieurs ensembles de données. La bibliothèque comprend plusieurs aides de couches (tflearn, tf-slim, skflow), qui la rendent encore plus fonctionnelle. TensorFlow s’enrichit constamment de nouvelles versions, notamment en corrigeant les éventuelles failles de sécurité ou en améliorant l’intégration de TensorFlow et du GPU. (lien github de TensorFlow https://github.com/tensorflow/tensorflow)\n",
    "\n",
    "## 15. XGBoost\n",
    "\n",
    "Utilisez cette bibliothèque pour mettre en œuvre des algorithmes de Machine Learning dans le framework du Gradient Boosting. XGBoost est portable, flexible et efficace. Il offre un boosting d’arbres parallèles qui aide les équipes à résoudre de nombreux problèmes de science des données. Un autre avantage est que les développeurs peuvent exécuter le même code sur les principaux environnements distribués tels que Hadoop, SGE et MPI. (lien github de XGBoost https://github.com/dmlc/xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422774c8-4624-4030-bd7d-1c0a9b64ad50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
